#JMM #Memory-Barriers 

##  不能让CPU闲着

- 考虑这么一个场景，`CPU 0` 和`CPU 1` 同时拥有某个缓存行，两个缓存行都处于`Shared`状态；
- `CPU 0` 想对自己的缓存行执行 *write* 操作，根据 [[MESI 协议]] `CPU 0` 必须先发送 `Invalidate` 消息让`CPU 1`中的*缓存行失效*。

![[CPU等待stall示意.gif]]
- 由于`CPU 0`必须等到`CPU 1`反馈了`Invalidate Acknowledge`之后才能确保自己可以操作缓存行，所以从发出`Invalidate`直到收到`Invalidate Acknowledge`的这段时间，`CPU 0`一直处于**阻塞等待(stall)状态**。
- CPU 是宝贵的资源，不能闲置，硬件工程师为了解决这个问题，引入了 `Store Buffers`。

###  引入Store Buffers
![[加入store buffer后的计算机数据架构图.png]]
- 在CPU和Cache之间添加了一个中间层——`Store Buffer`。
- 当`CPU 0` 执行 *write* 指令时：
	1. 先把想要 *write* 的值写入到`Store Buffer`中；
	2. 再继续执行其他任务，无需等待`CPU 1`。
	3. `CPU 1` 返回之后，`CPU 0` 再将 `Store Buffer` 中的最新值写入到缓存行中。
- `Store Buffers`的引入解决了CPU闲置的问题，又引出了3个新问题。


### Store Buffers引起的不一致问题

![[storebuffer 引入的不一致问题.png]]

- 上图左侧的代码，其中`a`和`b`的初始值为0，在大多数时候，最后的断言会为 True。
- 左侧的代码在某个场景下可能会出现不符合预期的情况（断言为False）。
- 假设含有变量 `a` 的缓存行已经存在于 `CPU 1` 的 Cache 中，含有变量 `b` 的缓存行已经存在于 `CPU 0` 的 Cache中。
- 引入`Store Buffers`之后的CPU架构来执行上面的代码，`CPU 0` `和CPU 1` 的操作顺序如下图所示：

![[引入storebuffer后CPU操作过程示意.png]]

1.  CPU 0 执行 `a = 1`;
2.  CPU 0 首先从自己的Cache中查找`a`，发现没有；
3.  CPU 0 发送 `Read Invalidate` 消息来获取含有 `a` 的缓存行，并通知其他 CPU，“我要用，你们都销毁！”；
4.  CPU 0 在`Store Buffer`中记录下自己想赋给`a`的值，即 `a = 1` 。此时 CPU 0 并不会阻塞，继续向下执行，此时 CPU 1 可能进行了操作，见第5步；
5.  CPU 1 收到来自CPU 0的 `Read Invalidate` 消息，于是把自己包含 `a` 的缓存行返回给 CPU 0，并且把自己的缓存行状态设置为 `Invalid`；
6.  CPU 0 开始执行 `b = a + 1`；
7.  CPU 0 收到来自CPU 1 的缓存行，并放到自己的缓存行中，其中`a`的值为0；此时CPU 0 的缓存行中的`a`和`b`的状态都是`Exclusive`，因为这些缓存行都由CPU 0 独占；
8.  CPU 0 **从缓存行中读取** `a`，此时值为0；
9.  CPU 0 根据自己之前在`Store Buffer`中存放的 `a = 1`来 更新自己Cache中的`a`，设置为1；
10.  CPU 0 在第8步获取的`a`值的基础上`+ 1`（此时不需要重新从缓存行中读取数据，因为读取的动作在第8步中已经做了），并更新自己缓存行中的`b`；此时包含`b`的缓存行的状态为 `Modified`；
11.  CPU 0 执行断言操作，发现断言为 False。

![[引入storebuffer后cpu不一致问题示意.gif]]
这确实是一件非常违反直觉的事情，我们本来以为CPU就是完全按照代码的顺序执行的（至少最终结果应该表现地像CPU是完全按照代码的顺序执行的一样），我们认为`b`的最终结果就应该是2。

出现这个问题的原因是`CPU 0` 运行过程中出现了`a`的两份数据拷贝，一份是在`Store Buffer`中，一份是在Cache中。为了不让软件工程师疯掉，继续保持软件代码的直观性，硬件工程师又引入了`Store Forwarding`来解决这个问题。

###  引入Store Forwarding

每个CPU在执行数据加载操作时都直接使用`Store Buffer`中的内容，而无需从Cache中获取，如下图所示。

![[引入storeforwarding后示意.png]]

请注意上图和原来图片的区别，上图中的`Store Buffer`中的数据可以直接被CPU读取。对应到上面的`CPU 0` 的操作步骤，就是第8步直接从`Store Buffer`中读取最新的`a`，而不是从Cache中读取，这样整个程序的最终断言结果就是True！

总之，引发的第1个问题，硬件工程师通过引入`Store Forwarding`为我们解决了。

### 6.4. Store Buffers引起的问题2

在多个CPU并发处理情况下也可能会导致代码运行出现问题。

同样也是举一个极端一点的例子。见下图左侧的代码，其中`a`和`b`的初始值为0，进一步假设含有变量`a`的缓存行已经存在于`CPU 1`的Cache中，含有变量`b`的缓存行已经存在于`CPU 0`的Cache中。`CPU 0` 执行`foo`方法，`CPU 1` 执行`bar`方法。正常情况下，`bar`方法中的断言结果应该为True。

![[storebuffer引入的乱序问题示意.png]]

然而，我们按照下图中的执行顺序操作一遍之后，断言却是False！
![[storebuffer导致的乱序问题示意.png]]

1.  CPU 0 执行`a = 1`，首先从自己的Cache查找啊，发现没有；
2.  CPU 0 将`a`的新值`1`写入到自己的`Store Buffer`中；
3.  CPU 0 发送`Read Invalidate`消息（从发出这个消息到CPU 1 接收到，期间又运行了非常多的步骤，见下方GIF图）；
4.  CPU 1 执行`while (b == 0) continue`，发现`b`不在自己的`Cache`中，于是发送`Read`消息；
5.  CPU 0 执行`b = 1`，由于`b`已经存在于自己的Cache中了，所以直接将Cache中的`b`修改为`1`，并修改包含`b`的缓存行的状态为`Modified`；
6.  CPU 0 收到来自第4步CPU 1 发出的`Read`消息，由于当前自己拥有的`b`是最新版本的，所以CPU 0 把含有`b`的缓存行返回给CPU 1，同时修改自己的缓存行状态为`Shared`；
7.  CPU 1 收到来自CPU 0 的`b`缓存行数据，放到自己的Cache中，并设置为`Shared`状态；
8.  CPU 1 结束`while`循环，因为此时的`b`值已经是`1`了；
9.  CPU 1 执行`assert(a == 1)`，由于Cache中的`a`值是`0`（此时还没收到来自CPU 0 的`Read Invalidate`消息，因此CPU 1 有理由认为自己的数据就是合法的），因此断言结果为False；
10.  CPU 1 终于收到来自CPU 0 的`Read Invalidate`消息了，虽然已经晚了（当然CPU压根不知道自己的这个消息接收的时机并不合适），但是还得按照约定把自己的`a`设置为`Invalid`状态，并且给CPU 0 发送`Invalidate Acknowledge`以及`Read Response`反馈；
11.  CPU 0 收到CPU 1 的反馈，利用`Store Buffer`中的值更新`a`。

![[storebuffer导致的乱序问题示意.gif]]


我们分析一下结果不符合我们预期的原因。

`Store Buffer`的加入导致`Read Invalidate`的发送是一个异步操作，异步可能导致的结果就是CPU 1 接收到CPU 0 的`Read Invalidate`消息太晚了，导致在Cache中的实际操作顺序是`b = 1`，最后才是`a = 1`，就好像**写操作被重排序**了一样，这就是**CPU的乱序执行**。

如果没有看懂上面一段就再看一下图片中的CPU 0 Cache的时间线演化。

很多人看到「乱序执行」唯恐避之不及，它当初可是为了提高CPU的工作效率而诞生的，而且在大多数情况下并不会导致什么错误，只是在多处理器（smp）并发执行的时候可能会出现问题，于是便有了下文。

也就是说，如果在第5步CPU 0 修改`b`之前，我们强制让CPU 0先完成对`a`的修改就可以了。

为了解决这样的问题，CPU提供了一些操作指令，来帮助我们避免这样的问题，就是大名鼎鼎的**内存屏障**（Memory Barrier,mb）。


###  内存屏障

我们稍微修改一下`foo`方法，在`b = 1`之前添加一条内存屏障指令`smp_mb()`。

![[CPU内存屏障示意.png]]

> 多说一点，`smp`的全称是Symmetrical Multi-Processing（对称多处理）技术，是指在一个计算机上汇集了一组处理器(多CPU)，各CPU之间共享内存子系统以及总线结构。

为什么要特意加上`smp`呢？因为即便现代处理器会乱序执行，但在单个CPU上，指令能通过指令队列顺序获取指令并执行，结果利用队列顺序返回寄存器，这使得程序执行时所有的内存访问操作看起来像是按程序代码编写的顺序执行的，因此没必要使用内存屏障（前提是不考虑编译器的优化的情况）。

内存屏障听起来很高大上，但是对于软件开发者而言其实非常简单，总结一句话就是：

**在内存屏障语句之后的所有针对Cache的写操作开始之前，必须先把Store Buffer中的数据全部刷新到Cache中。**

如果你看明白了我上面说的`Store Buffer`，这句话是不是贼好懂呢？换个角度再翻译一下，就是一定要保证**存到Store Buffer中的数据有序地刷新到Cache中**，这样就可以避免发生指令重排序了。

如何保证有序呢？

最简单的方式就是让CPU傻等，`CPU 0` 在执行第5步之前必须等着`CPU 1`给出反馈，直到清空自己的`Store Buffer`，然后才能继续向下执行。

啥？又让CPU闲着？一切让CPU闲置的方法都是馊主意！

还有一个办法就是让数据在`Store Buffer`中排队，谁先进入就必须先刷新谁，后边的必须等着！

**这样一来，本来可以直接写入Cache的操作（比如待操作的数据已经存在于自己的Cache中了）也必须先存到Store Buffer，然后依序进行刷新**。


# 内存屏障
为什么要特意加上`smp`呢？因为即便现代处理器会乱序执行，但在单个CPU上，指令能通过指令队列顺序获取指令并执行，结果利用队列顺序返回寄存器，这使得程序执行时所有的内存访问操作看起来像是按程序代码编写的顺序执行的，因此没必要使用内存屏障（前提是不考虑编译器的优化的情况）。

内存屏障听起来很高大上，但是对于软件开发者而言其实非常简单，总结一句话就是：

**在内存屏障语句之后的所有针对Cache的写操作开始之前，必须先把Store Buffer中的数据全部刷新到Cache中。**

如果你看明白了我上面说的`Store Buffer`，这句话是不是贼好懂呢？换个角度再翻译一下，就是一定要保证**存到Store Buffer中的数据有序地刷新到Cache中**，这样就可以避免发生指令重排序了。

如何保证有序呢？

最简单的方式就是让CPU傻等，`CPU 0` 在执行第5步之前必须等着`CPU 1`给出反馈，直到清空自己的`Store Buffer`，然后才能继续向下执行。

啥？又让CPU闲着？一切让CPU闲置的方法都是馊主意！

还有一个办法就是让数据在`Store Buffer`中排队，谁先进入就必须先刷新谁，后边的必须等着！

**这样一来，本来可以直接写入Cache的操作（比如待操作的数据已经存在于自己的Cache中了）也必须先存到Store Buffer，然后依序进行刷新**。


# 参考
1. [说透缓存一致性与内存屏障](https://www.cnblogs.com/chanmufeng/p/16523365.html)